{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"heart_2020_cleaned.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "MinMaxScaler.__init__() got an unexpected keyword argument 'with_mean'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      8\u001b[39m numeric_transformer = Pipeline(steps=[\n\u001b[32m      9\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mscaler\u001b[39m\u001b[33m\"\u001b[39m, MinMaxScaler())\n\u001b[32m     10\u001b[39m ])\n\u001b[32m     12\u001b[39m categorical_transformer = Pipeline(steps=[\n\u001b[32m     13\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33monehot\u001b[39m\u001b[33m\"\u001b[39m, OneHotEncoder(handle_unknown=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     14\u001b[39m ])\n\u001b[32m     16\u001b[39m preprocessing = ColumnTransformer(\n\u001b[32m     17\u001b[39m     transformers=[\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mnumerical\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mMinMaxScaler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwith_mean\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m, numeric_columns),\n\u001b[32m     19\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mcategorical\u001b[39m\u001b[33m\"\u001b[39m, OneHotEncoder(handle_unknown=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m), categorical_columns),\n\u001b[32m     20\u001b[39m     ]\n\u001b[32m     21\u001b[39m )\n",
            "\u001b[31mTypeError\u001b[39m: MinMaxScaler.__init__() got an unexpected keyword argument 'with_mean'"
          ]
        }
      ],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "numeric_columns = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "categorical_columns = df.select_dtypes(include=[\"object\"]).columns.drop(\"HeartDisease\")\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    (\"scaler\", MinMaxScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "preprocessing = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"numerical\", MinMaxScaler(), numeric_columns),\n",
        "        (\"categorical\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_columns),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop('HeartDisease', axis=1)\n",
        "y = (df['HeartDisease'] == \"Yes\").astype(int)\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "X_test, X_val, y_test, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "model = Pipeline(steps=[\n",
        "    (\"preprocessing\", preprocessing),\n",
        "    (\"clf\", MLPClassifier(hidden_layer_sizes=(128, 64), activation='relu', solver='adam',\n",
        "                           batch_size=1024, learning_rate_init=0.001, max_iter=20,\n",
        "                           early_stopping=True, n_iter_no_change=3, random_state=42))\n",
        "])\n",
        "\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    balanced_accuracy_score,\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    RocCurveDisplay,\n",
        "    PrecisionRecallDisplay,\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec_macro = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
        "rec_macro = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
        "f1_macro = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
        "prec_weighted = precision_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
        "rec_weighted = recall_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
        "f1_weighted = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
        "bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_proba)\n",
        "ap = average_precision_score(y_test, y_proba)\n",
        "\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"Balanced accuracy: {bal_acc:.4f}\")\n",
        "print(f\"Precision (macro): {prec_macro:.4f}\")\n",
        "print(f\"Recall (macro): {rec_macro:.4f}\")\n",
        "print(f\"F1 (macro): {f1_macro:.4f}\")\n",
        "print(f\"Precision (weighted): {prec_weighted:.4f}\")\n",
        "print(f\"Recall (weighted): {rec_weighted:.4f}\")\n",
        "print(f\"F1 (weighted): {f1_weighted:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
        "print(f\"Average Precision (PR-AUC): {ap:.4f}\")\n",
        "\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "RocCurveDisplay.from_predictions(y_test, y_proba, ax=axes[0])\n",
        "axes[0].set_title(\"ROC curve\")\n",
        "PrecisionRecallDisplay.from_predictions(y_test, y_proba, ax=axes[1])\n",
        "axes[1].set_title(\"Precision-Recall curve\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ai-projekat",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
